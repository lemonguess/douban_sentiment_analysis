# -*- coding: utf-8 -*-

import pickle
import numpy as np
import jieba
from models.logistic_regression import LogisticRegression
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from utils import load_corpus, review_to_text

jieba.load_userdict("./data/userdict.txt")

file_path = './data/review.csv'
model_export_path = './checkpoint/logistic_regression.pkl'
stopword_path = './data/stopwords.txt'


def train():
    review_list, sentiment_list = load_corpus(file_path)
    # å°†æ ‡ç­¾è½¬æ¢ä¸º0/1æ ¼å¼
    sentiment_list = [1 if s == 'æ­£é¢' else 0 for s in sentiment_list]

    # åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
    n = len(review_list) // 5
    train_reviews, train_labels = review_list[n:], sentiment_list[n:]
    test_reviews, test_labels = review_list[:n], sentiment_list[:n]

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_reviews)}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_reviews)}")
    print("-" * 50)

    # æ–‡æœ¬å‘é‡åŒ–
    vectorizer = CountVectorizer(max_df=0.8, min_df=3)
    tfidftransformer = TfidfTransformer()

    # å¤„ç†æ–‡æœ¬
    processed_reviews = [' '.join(review_to_text(r)) for r in train_reviews]
    X_train = vectorizer.fit_transform(processed_reviews)
    X_train_tfidf = tfidftransformer.fit_transform(X_train)

    print("å¼€å§‹è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹...")
    print("-" * 50)

    # è®­ç»ƒæ¨¡å‹
    model = LogisticRegression(
        learning_rate=0.1,
        num_iterations=20,
        reg_lambda=0.01
    )
    model.fit(X_train_tfidf, train_labels)

    print("-" * 50)
    print("è®­ç»ƒå®Œæˆï¼Œå¼€å§‹æµ‹è¯•...")

    # æµ‹è¯•é›†éªŒè¯
    processed_test = [' '.join(review_to_text(r)) for r in test_reviews]
    X_test = vectorizer.transform(processed_test)
    X_test_tfidf = tfidftransformer.transform(X_test)

    predictions = model.predict(X_test_tfidf)
    accuracy = accuracy_score(test_labels, predictions)

    # çªå‡ºæ˜¾ç¤ºæµ‹è¯•é›†å‡†ç¡®ç‡
    print("=" * 60)
    print("ğŸ¯ æµ‹è¯•é›†è¯„ä¼°ç»“æœ")
    print("=" * 60)
    print(f"ğŸ“Š æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")
    print("=" * 60)


    # æ··æ·†çŸ©é˜µ
    print("\nğŸ“ˆ æ··æ·†çŸ©é˜µ:")
    cm = confusion_matrix(test_labels, predictions)
    print(cm)
    print(f"çœŸè´Ÿä¾‹(TN): {cm[0, 0]}, å‡æ­£ä¾‹(FP): {cm[0, 1]}")
    print(f"å‡è´Ÿä¾‹(FN): {cm[1, 0]}, çœŸæ­£ä¾‹(TP): {cm[1, 1]}")

    # è®¡ç®—å…¶ä»–æŒ‡æ ‡
    precision = cm[1, 1] / (cm[1, 1] + cm[0, 1]) if (cm[1, 1] + cm[0, 1]) > 0 else 0
    recall = cm[1, 1] / (cm[1, 1] + cm[1, 0]) if (cm[1, 1] + cm[1, 0]) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    print(f"\nğŸ“Š å…¶ä»–è¯„ä¼°æŒ‡æ ‡:")
    print(f"ç²¾ç¡®ç‡(Precision): {precision:.4f}")
    print(f"å¬å›ç‡(Recall): {recall:.4f}")
    print(f"F1åˆ†æ•°: {f1:.4f}")

    # é”™è¯¯æ ·ä¾‹å±•ç¤ºï¼ˆé™åˆ¶æ˜¾ç¤ºæ•°é‡ï¼‰
    print("\nâŒ é”™è¯¯é¢„æµ‹æ ·ä¾‹ (å‰5ä¸ª):")
    error_count = 0
    for i, (pred, true, text) in enumerate(zip(predictions, test_labels, test_reviews)):
        if pred != true and error_count < 5:
            error_count += 1
            sentiment_map = {0: 'è´Ÿé¢', 1: 'æ­£é¢'}
            print(f"æ ·ä¾‹ {error_count}:")
            print(f"  é¢„æµ‹: {sentiment_map[pred[0]]}")
            print(f"  çœŸå®: {sentiment_map[true]}")
            print(f"  æ–‡æœ¬: {text[:80]}...")
            print("-" * 40)

    # ä¿å­˜æ¨¡å‹
    with open(model_export_path, 'wb') as file:
        d = {
            "model": model,
            "vectorizer": vectorizer,
            "tfidftransformer": tfidftransformer,
            "classes": [0, 1],
            "accuracy": accuracy  # ä¿å­˜å‡†ç¡®ç‡
        }
        pickle.dump(d, file)

    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {model_export_path}")
    print(f"ğŸ¯ æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")

    return accuracy


def test_analyzer():
    """
    æµ‹è¯•è®­ç»ƒå¥½çš„é€»è¾‘å›å½’åˆ†ç±»å™¨
    """
    print("ğŸ”„ æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")

    # åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    try:
        with open(model_export_path, 'rb') as file:
            model_data = pickle.load(file)
            clf = model_data["model"]
            vectorizer = model_data["vectorizer"]
            tfidftransformer = model_data["tfidftransformer"]
            classes = model_data["classes"]

            # å¦‚æœæ¨¡å‹ä¸­ä¿å­˜äº†å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºæ¥
            if "accuracy" in model_data:
                print(f"ğŸ“Š æ¨¡å‹è®­ç»ƒæ—¶çš„æµ‹è¯•é›†å‡†ç¡®ç‡: {model_data['accuracy']:.4f} ({model_data['accuracy'] * 100:.2f}%)")

        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    except FileNotFoundError:
        print("âŒ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒç¨‹åº!")
        return None
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

    def analyze_text(text):
        """
        åˆ†æå•ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿ
        """
        try:
            # é¢„å¤„ç†æ–‡æœ¬
            processed_text = ' '.join(review_to_text(text))

            # è½¬æ¢ä¸ºç‰¹å¾å‘é‡
            X = vectorizer.transform([processed_text])
            X_tfidf = tfidftransformer.transform(X)

            # é¢„æµ‹
            prediction = clf.predict(X_tfidf)[0]
            probabilities = clf.predict_proba(X_tfidf)[0]

            # æ„å»ºç»“æœ
            result = {
                'text': text,
                'prediction': prediction,
                'sentiment': 'æ­£é¢' if prediction == 1 else 'è´Ÿé¢',
                'confidence': float(max(probabilities))
            }

            return result

        except Exception as e:
            print(f"âŒ æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
            return None

    # æµ‹è¯•æ ·ä¾‹
    test_texts = [
        'å€æ„Ÿå¤±æœ›çš„ä¸€éƒ¨è¯ºå…°çš„ç”µå½±ï¼Œæ„Ÿè§‰æ›´åƒæ˜¯ç›—æ¢¦å¸®çš„ä¸€åœºå¤§æ‚çƒ©ã€‚è™½ç„¶çœ‹ä¹‹å‰å°±çŸ¥é“è‚¯å®šæ˜¯ä¸€éƒ¨æ— æ³•è¶…è¶Šå‰ä¼ 2çš„è™è ç‹­ï¼Œä½†çœŸå¿ƒæ²¡æƒ³åˆ°èƒ½å·®åˆ°è¿™ä¸ªåœ°æ­¥ã€‚èŠ‚å¥çš„æŠŠæ§çš„å¤±è¯¯å’Œè§’è‰²çš„å®šä½æ¨¡ç³Šç»å¯¹æ˜¯æ•´éƒ¨å½±ç‰‡çš„ç¡¬ä¼¤ã€‚',
        'è¿™éƒ¨ç”µå½±çœŸçš„å¤ªæ£’äº†ï¼å‰§æƒ…ç´§å‡‘ï¼Œæ¼”å‘˜æ¼”æŠ€ç²¾æ¹›ï¼Œç‰¹æ•ˆä¹Ÿå¾ˆéœ‡æ’¼ã€‚å¼ºçƒˆæ¨èå¤§å®¶å»çœ‹ï¼',
        'è¿˜å¯ä»¥å§ï¼Œæ²¡æœ‰ç‰¹åˆ«æƒŠè‰³ï¼Œä½†ä¹Ÿä¸ç®—å¤ªå·®ã€‚ä¸­è§„ä¸­çŸ©çš„ä¸€éƒ¨ç”µå½±ã€‚',
        'æ¼”å‘˜è¡¨æ¼”å¾ˆè‡ªç„¶ï¼Œæ•…äº‹æƒ…èŠ‚å¼•äººå…¥èƒœï¼Œæ˜¯ä¸€éƒ¨å€¼å¾—è§‚çœ‹çš„å¥½ç”µå½±ã€‚',
        'å‰§æƒ…æ‹–æ²“ï¼Œæ¼”æŠ€å°´å°¬ï¼Œå®Œå…¨æ˜¯åœ¨æµªè´¹æ—¶é—´ï¼Œä¸æ¨èè§‚çœ‹ã€‚'
    ]

    print("\n" + "=" * 70)
    print("ğŸ­ é€»è¾‘å›å½’æƒ…æ„Ÿåˆ†ææµ‹è¯•ç»“æœ")
    print("=" * 70)

    results = []
    for i, text in enumerate(test_texts, 1):
        result = analyze_text(text)
        if result:
            results.append(result)

            # æ ¹æ®ç½®ä¿¡åº¦è®¾ç½®æ˜¾ç¤ºæ ·å¼
            confidence_emoji = "ğŸ”¥" if result['confidence'] > 0.8 else "ğŸ‘" if result['confidence'] > 0.6 else "ğŸ¤”"
            sentiment_emoji = "ğŸ˜Š" if result['prediction'] == 1 else "ğŸ˜"

            print(f"\nğŸ“ æµ‹è¯•æ ·ä¾‹ {i}:")
            print(f"æ–‡æœ¬: {text[:60]}{'...' if len(text) > 60 else ''}")
            print(f"é¢„æµ‹ç»“æœ: {sentiment_emoji} {result['sentiment']} {confidence_emoji}")
            print(f"ç½®ä¿¡åº¦: {result['confidence']:.4f} ({result['confidence'] * 100:.2f}%)")
            # print("æ¦‚ç‡åˆ†å¸ƒ:")
            # for label, prob in result['probabilities'].items():
            #     bar_length = int(prob * 20)  # ç®€å•çš„è¿›åº¦æ¡
            #     bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
            #     print(f"  {label}: {prob:.4f} |{bar}| {prob * 100:.2f}%")
            # print("-" * 50)

    # ç»Ÿè®¡åˆ†æç»“æœ
    if results:
        positive_count = sum(1 for r in results if r['prediction'] == 1)
        negative_count = len(results) - positive_count
        avg_confidence = sum(r['confidence'] for r in results) / len(results)

        print(f"\nğŸ“Š æµ‹è¯•æ ·ä¾‹ç»Ÿè®¡:")
        print(f"æ­£é¢æƒ…æ„Ÿ: {positive_count} ä¸ª")
        print(f"è´Ÿé¢æƒ…æ„Ÿ: {negative_count} ä¸ª")
        print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.4f} ({avg_confidence * 100:.2f}%)")

    return analyze_text


# åœ¨ä¸»ç¨‹åºæœ€åæ·»åŠ æµ‹è¯•
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è®­ç»ƒé€»è¾‘å›å½’æƒ…æ„Ÿåˆ†ææ¨¡å‹")
    print("=" * 60)

    # è®­ç»ƒæ¨¡å‹å¹¶è·å–å‡†ç¡®ç‡
    final_accuracy = train()

    # print("\n" + "=" * 60)
    # print("âœ… è®­ç»ƒå®Œæˆ!")
    # print(f"ğŸ† æœ€ç»ˆæµ‹è¯•é›†å‡†ç¡®ç‡: {final_accuracy:.4f} ({final_accuracy * 100:.2f}%)")
    # print("=" * 60)
    #
    # # å¯é€‰ï¼šè¿è¡Œæµ‹è¯•åˆ†æå™¨
    # print("\nğŸ” è¿è¡Œæƒ…æ„Ÿåˆ†ææµ‹è¯•...")
    # analyzer = test_analyzer()
    #
    # # å•ç‹¬æµ‹è¯•æŒ‡å®šæ–‡æœ¬
    # text = 'å€æ„Ÿå¤±æœ›çš„ä¸€éƒ¨è¯ºå…°çš„ç”µå½±ï¼Œæ„Ÿè§‰æ›´åƒæ˜¯ç›—æ¢¦å¸®çš„ä¸€åœºå¤§æ‚çƒ©ã€‚è™½ç„¶çœ‹ä¹‹å‰å°±çŸ¥é“è‚¯å®šæ˜¯ä¸€éƒ¨æ— æ³•è¶…è¶Šå‰ä¼ 2çš„è™è ç‹­ï¼Œä½†çœŸå¿ƒæ²¡æƒ³åˆ°èƒ½å·®åˆ°è¿™ä¸ªåœ°æ­¥ã€‚èŠ‚å¥çš„æŠŠæ§çš„å¤±è¯¯å’Œè§’è‰²çš„å®šä½æ¨¡ç³Šç»å¯¹æ˜¯æ•´éƒ¨å½±ç‰‡çš„ç¡¬ä¼¤ã€‚'
    # result = analyzer(text)
    #
    # print("\n" + "=" * 60)
    # print("ğŸ¯ æŒ‡å®šæ–‡æœ¬åˆ†æç»“æœ:")
    # print("=" * 60)
    # print(f"æ–‡æœ¬: {text}")
    # print(f"é¢„æµ‹ç»“æœ: {'æ­£é¢' if result['prediction'] == 1 else 'è´Ÿé¢'}")
